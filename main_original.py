import os

os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"
import cv2
import numpy as np
import time
import argparse
from enum import Enum

from utils import config, UIHelper
from calibration import calibrate_cameras
from detector import BufferedImageProcessor, StereoProcessor
from predictor import TrajectoryPredictor, CourtBoundaryAnalyzer
from visualization_3d import Interactive3DVisualizer
from network_camera import NetworkCameraManager
from video_controls import EnhancedVideoControls


class SystemState(Enum):
    """ç³»ç»ŸçŠ¶æ€æšä¸¾"""
    BUFFERING = "buffering"
    PROCESSING = "processing"
    PREDICTION_READY = "prediction_ready"
    PREDICTION_COMPLETE = "prediction_complete"


class BufferedBadmintonSystem:
    """åŸºäºå›¾åƒç¼“å†²çš„ç¾½æ¯›çƒè½ç‚¹é¢„æµ‹ç³»ç»Ÿ - å®Œå…¨ä¿®å¤ç‰ˆ"""

    def __init__(self):
        """åˆå§‹åŒ–ç³»ç»Ÿ"""
        self.state = SystemState.BUFFERING
        self.running = False
        self.calibration_done = False

        # è§†é¢‘å’Œç›¸æœºå‚æ•°
        self.video_path1 = None
        self.video_path2 = None
        self.camera1_params_file = None
        self.camera2_params_file = None
        
        # æ–°å¢ï¼šç½‘ç»œæ‘„åƒå¤´æ”¯æŒ
        self.camera_url1 = None
        self.camera_url2 = None
        self.network_mode = False
        self.timestamp_header = "X-Timestamp"

        # æ ¸å¿ƒæ¨¡å—
        self.buffered_processor = None
        self.stereo_processor = None
        self.trajectory_predictor = None
        self.court_analyzer = None
        self.interactive_3d_viz = None

        # è§†é¢‘æ•è·
        self.cap1 = None
        self.cap2 = None
        self.network_camera_manager = None
        
        # æ–°å¢ï¼šè§†é¢‘æ§åˆ¶ç»„ä»¶
        self.video_controls = None

        # å¸§ç‡æ§åˆ¶
        self.video_fps = 30.0
        self.frame_time = 1.0 / self.video_fps
        self.last_frame_time = 0
        self.playback_speed = 1.0

        # æš‚åœæ§åˆ¶ - å¢å¼ºçŠ¶æ€ç®¡ç†
        self.paused = False
        self.pause_requested = False

        # æ•°æ®å’ŒçŠ¶æ€
        self.frame_count = 0
        self.actual_fps = 0
        self.fps_counter = 0
        self.fps_prev_time = time.time()

        # é¢„æµ‹ç»“æœå’Œæ§åˆ¶ - å¢å¼ºç®¡ç†
        self.prediction_result = None
        self.last_prediction_time = 0
        self.prediction_cooldown = 2.0  # å‡å°‘å†·å´æ—¶é—´
        self.processing_lock = False  # å¤„ç†é”æ ‡å¿—

        # è½¨è¿¹æ•°æ®ä¿å­˜
        self.current_trajectory_data = None

        # å½“å‰å¸§ç¼“å­˜ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
        self.current_frame1 = None
        self.current_frame2 = None

        # ç³»ç»Ÿæ€§èƒ½ç›‘æ§
        self.system_start_time = time.time()
        self.total_predictions = 0
        self.successful_predictions = 0
        
        # è§†é¢‘æ§åˆ¶ç›¸å…³
        self.total_frames = 0
        self.current_frame_index = 0
        self.seek_requested = False
        self.seek_frame = 0

        print("=" * 80)
        print("Enhanced Buffered Badminton System v5.2 - Network Camera Support")
        print(f"Initialized at: {time.strftime('%Y-%m-%d %H:%M:%S')} UTC")
        print(f"Current User: Liao-cyber360")
        print("Key Features: Network cameras, Progress bar, Multi-object tracking")
        print("=" * 80)

    def initialize_system(self, video_path1, video_path2):
        """åˆå§‹åŒ–ç³»ç»Ÿ - å¢å¼ºç‰ˆæœ¬"""
        print("ğŸš€ Initializing enhanced buffered badminton analysis system...")

        UIHelper.display_splash_screen(3)

        self.video_path1 = video_path1
        self.video_path2 = video_path2

        # éªŒè¯è§†é¢‘æ–‡ä»¶
        if not os.path.exists(video_path1):
            raise FileNotFoundError(f"Video file not found: {video_path1}")
        if not os.path.exists(video_path2):
            raise FileNotFoundError(f"Video file not found: {video_path2}")

        # æ‰“å¼€è§†é¢‘æ•è·
        self.cap1 = cv2.VideoCapture(video_path1)
        self.cap2 = cv2.VideoCapture(video_path2)

        if not self.cap1.isOpened():
            raise ValueError(f"Cannot open video file: {video_path1}")
        if not self.cap2.isOpened():
            raise ValueError(f"Cannot open video file: {video_path2}")

        # è·å–è§†é¢‘ä¿¡æ¯
        fps1 = self.cap1.get(cv2.CAP_PROP_FPS)
        fps2 = self.cap2.get(cv2.CAP_PROP_FPS)
        frame_count1 = int(self.cap1.get(cv2.CAP_PROP_FRAME_COUNT))
        frame_count2 = int(self.cap2.get(cv2.CAP_PROP_FRAME_COUNT))

        self.video_fps = min(fps1, fps2) if fps1 > 0 and fps2 > 0 else 30.0
        self.frame_time = 1.0 / self.video_fps
        self.total_frames = min(frame_count1, frame_count2)

        print(f"ğŸ“¹ Video Information:")
        print(f"   Camera 1: {fps1:.1f} FPS, {frame_count1} frames")
        print(f"   Camera 2: {fps2:.1f} FPS, {frame_count2} frames")
        print(f"   Using playback FPS: {self.video_fps:.1f}")
        print(f"   Total frames: {self.total_frames}")

        # åˆå§‹åŒ–è§†é¢‘æ§åˆ¶ç»„ä»¶
        self.video_controls = EnhancedVideoControls(video_width=1280)
        self.video_controls.set_video_info(self.total_frames, self.video_fps)

        # åˆå§‹åŒ–æ ¸å¿ƒæ¨¡å—
        self._initialize_core_modules()

        print("âœ… Enhanced system initialization complete!")
        print(f"ğŸ“Š System ready for operation at {time.strftime('%H:%M:%S')} UTC")
        return True

    def _initialize_core_modules(self):
        """åˆå§‹åŒ–æ ¸å¿ƒæ¨¡å—"""
        print("ğŸ”§ Initializing core modules...")

        # ç¼“å†²å¤„ç†å™¨
        self.buffered_processor = BufferedImageProcessor(
            config.yolo_ball_model,
            buffer_duration=5.0,
            fps=self.video_fps
        )

        # åŒç›®å¤„ç†å™¨
        self.stereo_processor = StereoProcessor()

        # è½¨è¿¹é¢„æµ‹å™¨
        self.trajectory_predictor = TrajectoryPredictor()

        # åœºåœ°åˆ†æå™¨
        self.court_analyzer = CourtBoundaryAnalyzer()

        # 3Då¯è§†åŒ–å™¨ - ä½¿ç”¨å¢å¼ºç‰ˆæœ¬
        self.interactive_3d_viz = Interactive3DVisualizer()
        self.interactive_3d_viz.start()

        print("âœ… Enhanced system initialization complete!")
        print(f"ğŸ“Š System ready for operation at {time.strftime('%H:%M:%S')} UTC")
        return True

    def initialize_network_cameras(self, camera_url1, camera_url2=None, timestamp_header="X-Timestamp"):
        """åˆå§‹åŒ–ç½‘ç»œæ‘„åƒå¤´ç³»ç»Ÿ"""
        print("ğŸŒ Initializing network camera system...")
        
        self.camera_url1 = camera_url1
        self.camera_url2 = camera_url2
        self.timestamp_header = timestamp_header
        self.network_mode = True
        
        # åˆ›å»ºç½‘ç»œæ‘„åƒå¤´ç®¡ç†å™¨
        self.network_camera_manager = NetworkCameraManager(
            camera_url1, camera_url2, timestamp_header
        )
        
        # å¯åŠ¨ç½‘ç»œæµ
        if not self.network_camera_manager.start():
            raise RuntimeError("Failed to start network camera streams")
        
        # ç­‰å¾…å‡ ç§’è®©æµç¨³å®š
        print("â³ Waiting for network streams to stabilize...")
        time.sleep(3)
        
        # è·å–FPSä¿¡æ¯
        self.video_fps = self.network_camera_manager.get_fps()
        if self.video_fps <= 0:
            self.video_fps = 30.0  # é»˜è®¤FPS
        self.frame_time = 1.0 / self.video_fps
        
        print(f"ğŸ“¹ Network Camera Information:")
        print(f"   Camera 1: {camera_url1}")
        if camera_url2:
            print(f"   Camera 2: {camera_url2}")
        print(f"   Timestamp header: {timestamp_header}")
        print(f"   Estimated FPS: {self.video_fps:.1f}")
        
        # åˆå§‹åŒ–æ ¸å¿ƒæ¨¡å—ï¼ˆä¸è§†é¢‘æ–‡ä»¶æ¨¡å¼ç›¸åŒï¼‰
        self._initialize_core_modules()
        
        print("âœ… Network camera system initialization complete!")
        print(f"ğŸ“Š System ready for network operation at {time.strftime('%H:%M:%S')} UTC")
        return True

    def calibration_mode(self):
        """ç›¸æœºæ ‡å®šæ¨¡å¼ - å¢å¼ºé”™è¯¯å¤„ç†ï¼Œæ”¯æŒè§†é¢‘å’Œå®æ—¶æ‘„åƒå¤´"""
        print("ğŸ¯ Starting enhanced camera calibration...")

        output_dir = os.path.join(config.results_dir, "calibration")
        os.makedirs(output_dir, exist_ok=True)

        try:
            if self.network_mode:
                # ç½‘ç»œæ‘„åƒå¤´æ ‡å®šæ¨¡å¼
                print("ğŸŒ Using network camera live feed calibration...")
                from calibration import calibrate_cameras_from_live_feed
                
                extrinsic_file1, extrinsic_file2 = calibrate_cameras_from_live_feed(
                    self.network_camera_manager, output_dir, num_frames=20, preview_time=5.0
                )
            else:
                # è§†é¢‘æ–‡ä»¶æ ‡å®šæ¨¡å¼
                print("ğŸ“¹ Using video file calibration...")
                from calibration import calibrate_cameras
                
                extrinsic_file1, extrinsic_file2 = calibrate_cameras(
                    self.video_path1, self.video_path2, output_dir
                )

            if not extrinsic_file1 or not extrinsic_file2:
                raise ValueError("Calibration files not generated properly")

            self.camera1_params_file = extrinsic_file1
            self.camera2_params_file = extrinsic_file2

            # éªŒè¯æ ‡å®šæ–‡ä»¶
            if not os.path.exists(extrinsic_file1) or not os.path.exists(extrinsic_file2):
                raise FileNotFoundError("Calibration files not found after generation")

            # åŠ è½½æ ‡å®šç»“æœ
            success = self.stereo_processor.load_camera_parameters(extrinsic_file1, extrinsic_file2)
            if not success:
                raise ValueError("Failed to load calibration parameters")

            self.calibration_done = True
            mode_text = "Network Camera" if self.network_mode else "Video File"
            print(f"âœ… {mode_text} calibration completed successfully!")
            print(f"   Camera 1 params: {extrinsic_file1}")
            print(f"   Camera 2 params: {extrinsic_file2}")
            return True

        except Exception as e:
            print(f"âŒ Calibration failed: {e}")
            import traceback
            traceback.print_exc()
            return False

    def load_existing_calibration(self, cam1_params, cam2_params):
        """åŠ è½½å·²æœ‰çš„æ ‡å®šå‚æ•° - å¢å¼ºéªŒè¯"""
        try:
            # éªŒè¯æ–‡ä»¶å­˜åœ¨
            if not os.path.exists(cam1_params):
                raise FileNotFoundError(f"Camera 1 parameters file not found: {cam1_params}")
            if not os.path.exists(cam2_params):
                raise FileNotFoundError(f"Camera 2 parameters file not found: {cam2_params}")

            print(f"ğŸ“ Loading calibration parameters...")
            print(f"   Camera 1: {cam1_params}")
            print(f"   Camera 2: {cam2_params}")

            self.camera1_params_file = cam1_params
            self.camera2_params_file = cam2_params

            success = self.stereo_processor.load_camera_parameters(cam1_params, cam2_params)
            if not success:
                raise ValueError("Failed to load camera parameters into stereo processor")

            self.calibration_done = True
            print("âœ… Existing calibration parameters loaded successfully!")
            return True

        except Exception as e:
            print(f"âŒ Failed to load calibration parameters: {e}")
            return False

    def _on_processing_complete(self, detections1, detections2, timestamps, frames1, frames2):
        """å¤„ç†å®Œæˆå›è°ƒ - å®Œå…¨é‡å†™ä¿®å¤"""
        try:
            print("ğŸ”„ Processing buffered frames...")
            current_time = time.time()

            # æ‰¹é‡ç”Ÿæˆ3Dç‚¹
            points_3d, timestamps_3d = self.stereo_processor.process_batch_detections(
                detections1, detections2, timestamps
            )

            # è·å–è°ƒè¯•æ•°æ®
            debug_data = self.stereo_processor.get_debug_data()

            # æ‰¾åˆ°æœ€ä½³è½¨è¿¹ç‰‡æ®µ - ä½¿ç”¨å¤šç›®æ ‡è·Ÿè¸ª
            best_trajectory, best_timestamps, confidence = \
                self.stereo_processor.get_best_trajectory_from_tracks(current_time)

            if best_trajectory is None or confidence < 0.3:
                print(f"âŒ Trajectory quality insufficient for prediction (confidence: {confidence:.2f})")
                print("   Trying fallback trajectory selection...")
                # å›é€€åˆ°ä¼ ç»Ÿæ–¹æ³•
                best_trajectory, best_timestamps, confidence = \
                    self.stereo_processor.find_best_trajectory_for_prediction(current_time)
                
                if best_trajectory is None or confidence < 0.3:
                    self._handle_prediction_failure(debug_data, "Insufficient trajectory quality")
                    return

            print(f"âœ… Found quality trajectory: {len(best_trajectory)} points, confidence: {confidence:.2f}")

            # æ‰§è¡Œé¢„æµ‹
            self.state = SystemState.PROCESSING
            self.total_predictions += 1

            prediction_result = self._predict_landing_point(best_trajectory, best_timestamps, confidence)

            if prediction_result is not None:
                self.successful_predictions += 1
                self._handle_prediction_success(
                    prediction_result, best_trajectory, best_timestamps,
                    confidence, points_3d, timestamps_3d, debug_data
                )
            else:
                print("âŒ Landing prediction computation failed")
                self._handle_prediction_failure(debug_data, "Prediction computation failed")

        except Exception as e:
            print(f"âŒ Critical error in processing callback: {e}")
            import traceback
            traceback.print_exc()
            self._handle_prediction_failure({}, f"Critical error: {str(e)}")

    def _handle_prediction_success(self, prediction_result, best_trajectory, best_timestamps,
                                   confidence, points_3d, timestamps_3d, debug_data):
        """å¤„ç†é¢„æµ‹æˆåŠŸ - å¢å¼ºç‰ˆæœ¬"""
        try:
            landing_position, in_bounds = prediction_result
            self.state = SystemState.PREDICTION_COMPLETE

            # ä¿å­˜å®Œæ•´è½¨è¿¹æ•°æ®
            self.current_trajectory_data = {
                'trajectory': best_trajectory,
                'timestamps': best_timestamps,
                'confidence': confidence,
                'all_points_3d': points_3d,
                'all_timestamps_3d': timestamps_3d,
                'debug_data': debug_data,
                'prediction_result': self.prediction_result,
                'prediction_time': time.time(),
                'success': True
            }

            # å‡†å¤‡è°ƒè¯•æ•°æ®ç”¨äºå¯è§†åŒ–
            debug_data['prediction_points'] = best_trajectory
            debug_data['prediction_timestamps'] = best_timestamps

            # æ›´æ–°3Då¯è§†åŒ–ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if self.interactive_3d_viz:
                try:
                    self.interactive_3d_viz.update_debug_data(debug_data)

                    predicted_trajectory = self.prediction_result.get('trajectory', [])
                    self.interactive_3d_viz.update_predicted_trajectory(predicted_trajectory)
                    self.interactive_3d_viz.update_landing_point(landing_position, in_bounds)

                    print("âœ… 3D visualization updated successfully")
                except Exception as viz_error:
                    print(f"âš ï¸ 3D visualization update error (non-critical): {viz_error}")

            # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
            self._display_prediction_result(landing_position, in_bounds, confidence)

            # æ‰“å°è¯¦ç»†è°ƒè¯•ä¿¡æ¯
            self._print_detailed_debug_info(debug_data, best_trajectory,
                                            self.prediction_result.get('trajectory', []))

        except Exception as e:
            print(f"âŒ Error handling prediction success: {e}")
            import traceback
            traceback.print_exc()
        finally:
            # ç¡®ä¿çŠ¶æ€è¢«é‡ç½®
            self._reset_processing_state()

    def _handle_prediction_failure(self, debug_data, reason="Unknown"):
        """å¤„ç†é¢„æµ‹å¤±è´¥ - å¢å¼ºç‰ˆæœ¬"""
        try:
            print(f"âŒ Prediction failed: {reason}")

            # ä¿å­˜å¤±è´¥æ•°æ®ç”¨äºè°ƒè¯•
            self.current_trajectory_data = {
                'success': False,
                'failure_reason': reason,
                'debug_data': debug_data,
                'failure_time': time.time()
            }

            # æ›´æ–°3Då¯è§†åŒ–æ˜¾ç¤ºè°ƒè¯•æ•°æ®ä½†æ²¡æœ‰é¢„æµ‹è½¨è¿¹
            if self.interactive_3d_viz:
                try:
                    debug_data['prediction_points'] = []
                    debug_data['prediction_timestamps'] = []
                    self.interactive_3d_viz.update_debug_data(debug_data)
                    self.interactive_3d_viz.update_predicted_trajectory([])

                    # æ‰“å°è°ƒè¯•ç»Ÿè®¡
                    self._print_detailed_debug_info(debug_data, [], [])
                except Exception as viz_error:
                    print(f"âš ï¸ 3D visualization error during failure handling: {viz_error}")

        except Exception as e:
            print(f"âŒ Error handling prediction failure: {e}")
        finally:
            # ç¡®ä¿çŠ¶æ€è¢«é‡ç½®
            self._reset_processing_state()

    def _reset_processing_state(self):
        """é‡ç½®å¤„ç†çŠ¶æ€ - é›†ä¸­åŒ–ç®¡ç†"""
        try:
            # é‡ç½®ç³»ç»ŸçŠ¶æ€
            self.state = SystemState.BUFFERING
            self.processing_lock = False

            # é‡ç½®ç¼“å†²å¤„ç†å™¨çŠ¶æ€
            if self.buffered_processor:
                self.buffered_processor.is_processing = False

            print("ğŸ”„ Processing state reset to BUFFERING")

        except Exception as e:
            print(f"âš ï¸ Error resetting processing state: {e}")
            # å¼ºåˆ¶é‡ç½®å…³é”®çŠ¶æ€
            self.state = SystemState.BUFFERING
            self.processing_lock = False

    def _predict_landing_point(self, trajectory_points, trajectory_timestamps, confidence):
        """é¢„æµ‹ç¾½æ¯›çƒè½åœ°ç‚¹ - å¢å¼ºé”™è¯¯å¤„ç†"""
        try:
            print(f"ğŸ¯ Starting landing point prediction...")
            print(f"   Input points: {len(trajectory_points)}")
            print(f"   Time span: {trajectory_timestamps[-1] - trajectory_timestamps[0]:.3f}s")

            landing_position, landing_time, predicted_trajectory = \
                self.trajectory_predictor.predict_landing_point(trajectory_points, trajectory_timestamps)

            if landing_position is None:
                print("âŒ Trajectory predictor returned None")
                return None

            # åˆ¤æ–­æ˜¯å¦åœ¨ç•Œå†…
            in_bounds = self.court_analyzer.is_point_in_court(landing_position, game_type='singles')

            # ä¿å­˜é¢„æµ‹ç»“æœ
            self.prediction_result = {
                'landing_point': landing_position,
                'landing_time': landing_time,
                'trajectory': predicted_trajectory,
                'in_bounds': in_bounds,
                'confidence': confidence,
                'prediction_timestamp': time.time()
            }

            print(f"âœ… Prediction computed successfully")
            print(f"   Landing point: ({landing_position[0]:.1f}, {landing_position[1]:.1f})")
            print(f"   Trajectory points: {len(predicted_trajectory) if predicted_trajectory else 0}")

            return landing_position, in_bounds

        except Exception as e:
            print(f"âŒ Error in landing point prediction: {e}")
            import traceback
            traceback.print_exc()
            return None

    def _display_prediction_result(self, landing_position, in_bounds, confidence):
        """æ˜¾ç¤ºé¢„æµ‹ç»“æœ - å¢å¼ºç‰ˆæœ¬"""
        current_time = time.strftime('%H:%M:%S')

        print(f"\n{'=' * 60}")
        print(f"ğŸ¯ PREDICTION RESULT - {current_time} UTC")
        print(f"{'=' * 60}")
        print(f"ğŸ“ Landing Position: ({landing_position[0]:.1f}, {landing_position[1]:.1f}) cm")
        print(f"ğŸ† Status: {'âœ… IN BOUNDS' if in_bounds else 'âŒ OUT OF BOUNDS'}")
        print(f"ğŸ² Confidence: {confidence:.2f}")
        print(f"ğŸ“Š Session Stats: {self.successful_predictions}/{self.total_predictions} successful")

        # æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯æ‘˜è¦
        if self.current_trajectory_data and 'debug_data' in self.current_trajectory_data:
            debug_data = self.current_trajectory_data['debug_data']
            print(f"\nğŸ“Š Debug Summary:")
            print(f"   Valid points used: {len(debug_data.get('all_valid_points', []))}")
            print(f"   Trajectory points: {len(debug_data.get('prediction_points', []))}")
            print(f"   Rejected points: {len(debug_data.get('rejected_points', []))}")

        print(f"\nğŸ“‹ Available Actions:")
        print(f"   V - Open 3D visualization with full debug data")
        print(f"   D - Print detailed debug statistics")
        print(f"   P - Resume video playback")
        print(f"   R - Reset system for new analysis")
        print(f"   1-6 - Toggle point types in 3D view (when open)")
        print(f"{'=' * 60}")

    def _print_detailed_debug_info(self, debug_data, selected_trajectory, predicted_trajectory):
        """æ‰“å°è¯¦ç»†è°ƒè¯•ä¿¡æ¯ - å¢å¼ºç‰ˆæœ¬"""
        print(f"\nğŸ“Š DETAILED DEBUG ANALYSIS:")
        print(f"{'â”€' * 50}")

        # æ•°æ®ç»Ÿè®¡
        all_points = len(debug_data.get('all_valid_points', []))
        selected_points = len(selected_trajectory) if selected_trajectory else 0
        predicted_points = len(predicted_trajectory) if predicted_trajectory else 0
        rejected_points = len(debug_data.get('rejected_points', []))
        low_quality = len(debug_data.get('low_quality_points', []))
        failed_triangulation = len(debug_data.get('triangulation_failed_points', []))

        print(f"ğŸ“ˆ Data Statistics:")
        print(f"   All valid points (150 frames): {all_points}")
        print(f"   Selected for prediction: {selected_points}")
        print(f"   Predicted trajectory points: {predicted_points}")
        print(f"   Rejected (out-of-bounds): {rejected_points}")
        print(f"   Low quality: {low_quality}")
        print(f"   Failed triangulation: {failed_triangulation}")

        # è½¨è¿¹è´¨é‡åˆ†æ
        if selected_trajectory and len(selected_trajectory) > 1:
            points = np.array(selected_trajectory)
            distances = [np.linalg.norm(points[i] - points[i - 1]) for i in range(1, len(points))]
            z_range = np.max(points[:, 2]) - np.min(points[:, 2])

            print(f"\nğŸ¯ Selected Trajectory Quality:")
            print(f"   Average point distance: {np.mean(distances):.1f} cm")
            print(f"   Height range: {z_range:.1f} cm")
            print(f"   Initial height: {points[0, 2]:.1f} cm")
            print(f"   Final height: {points[-1, 2]:.1f} cm")
            print(f"   Height drop: {points[0, 2] - points[-1, 2]:.1f} cm")

        # é¢„æµ‹è½¨è¿¹åˆ†æ
        if predicted_trajectory and len(predicted_trajectory) > 0:
            print(f"\nğŸ² Prediction Analysis:")
            print(f"   Predicted trajectory length: {len(predicted_trajectory)}")

            if len(predicted_trajectory) > 1:
                start_pos = predicted_trajectory[0]['position'] if isinstance(predicted_trajectory[0], dict) else \
                predicted_trajectory[0]
                end_pos = predicted_trajectory[-1]['position'] if isinstance(predicted_trajectory[-1], dict) else \
                predicted_trajectory[-1]

                horizontal_distance = np.linalg.norm(np.array(end_pos[:2]) - np.array(start_pos[:2]))
                print(f"   Horizontal prediction distance: {horizontal_distance:.1f} cm")

        print(f"{'â”€' * 50}")

    def start_processing(self):
        """å¼€å§‹å¤„ç†è§†é¢‘ - å®Œå…¨é‡å†™çš„ä¸»å¾ªç¯"""
        if not self.calibration_done:
            print("âš ï¸ Warning: Cameras not calibrated. System may not work properly.")
            return

        # åˆ›å»ºä¸»æ˜¾ç¤ºçª—å£
        cv2.namedWindow('Enhanced Badminton System - Live View', cv2.WINDOW_NORMAL)
        cv2.resizeWindow('Enhanced Badminton System - Live View', 1280, 640)

        # åˆå§‹åŒ–è¿è¡ŒçŠ¶æ€
        self.running = True
        self.state = SystemState.BUFFERING
        self.last_frame_time = time.time()
        self.fps_prev_time = time.time()

        print(f"\n{'=' * 80}")
        print(f"ğŸš€ STARTING ENHANCED VIDEO PROCESSING at {self.video_fps:.1f} FPS")
        print(f"Session started: {time.strftime('%Y-%m-%d %H:%M:%S')} UTC")
        print(f"User: Liao-cyber360")
        print(f"{'=' * 80}")

        self._print_control_instructions()

        # ä¸»å¤„ç†å¾ªç¯
        try:
            while self.running:
                loop_start_time = time.time()

                # 1. å¤„ç†æš‚åœçŠ¶æ€
                if self.paused:
                    self._handle_paused_state()
                    continue

                # 2. å¸§ç‡æ§åˆ¶
                if not self._should_process_frame(loop_start_time):
                    # åœ¨ç­‰å¾…æœŸé—´å¤„ç†èƒŒæ™¯ä»»åŠ¡
                    self._handle_background_tasks()
                    continue

                # 3. è¯»å–å’Œå¤„ç†è§†é¢‘å¸§
                if not self._process_video_frame():
                    print("ğŸ“¹ End of video reached")
                    break

                # 4. æ›´æ–°æ˜¾ç¤º
                self._update_display()

                # 5. å¤„ç†èƒŒæ™¯ä»»åŠ¡
                self._handle_background_tasks()

                # 6. æ€§èƒ½ç›‘æ§
                self._monitor_performance()

        except KeyboardInterrupt:
            print(f"\n{'=' * 80}")
            print("âš ï¸ Program interrupted by user (Ctrl+C)")
            print(f"Session ended: {time.strftime('%Y-%m-%d %H:%M:%S')} UTC")
            print(f"{'=' * 80}")
        except Exception as e:
            print(f"âŒ Critical error in main processing loop: {e}")
            import traceback
            traceback.print_exc()
        finally:
            self._cleanup()

    def _print_control_instructions(self):
        """æ‰“å°æ§åˆ¶è¯´æ˜ - å®Œæ•´ç‰ˆæœ¬ï¼ŒåŒ…å«æ–°åŠŸèƒ½"""
        print("\nğŸ“‹ ENHANCED SYSTEM CONTROLS:")
        print("   â–¶ï¸  SPACE     - Pause/Resume video playback")
        print("   ğŸ¯ T         - Trigger trajectory analysis (when paused)")
        print("   â–¶ï¸  P         - Resume playback (when paused)")
        
        if not self.network_mode:
            print("   ğŸ® MOUSE     - Drag progress bar to seek video position")
            print("   ğŸ“ CLICK     - Click progress bar to jump to position")
        else:
            print("   ğŸ“¡ NETWORK   - Network camera mode (seeking disabled)")
        
        print("   ğŸ” V         - Toggle 3D visualization window")
        print("   âŒ Q         - Close 3D visualization window")
        print("   ğŸ“Š D         - Print detailed debug statistics")
        print("   â“ H         - Show complete help screen")
        print("   ğŸ”„ R         - Complete system reset")
        print("   â© +/=       - Increase playback speed")
        print("   âª -/_       - Decrease playback speed")
        print("   ğŸ”„ 0         - Reset playback speed")
        print("   ğŸšª ESC       - Exit program")
        print("\nğŸ”§ 3D VISUALIZATION CONTROLS (when window open):")
        print("   1 - Toggle all valid points (light green)")
        print("   2 - Toggle prediction points (dark blue)")
        print("   3 - Toggle rejected points (red)")
        print("   4 - Toggle low quality points (orange)")
        print("   5 - Toggle triangulation failed (gray)")
        print("   6 - Toggle predicted trajectory (cyan line)")
        print("\nğŸ¸ NEW FEATURES v5.2:")
        print("   â€¢ Multi-shuttlecock detection and tracking")
        print("   â€¢ Maximum ball speed calculation before landing")
        print("   â€¢ Network camera MJPEG stream support")
        print("   â€¢ Draggable progress bar for video seeking")
        print("   â€¢ Intelligent mode switching (video/camera)")
        print("\nğŸ’¡ RECOMMENDED WORKFLOW:")
        if self.network_mode:
            print("   1. Monitor network stream â†’ 2. SPACE to pause buffering â†’ 3. T to predict â†’ 4. V for 3D")
        else:
            print("   1. Use progress bar to find trajectory â†’ 2. SPACE to pause â†’ 3. T to predict â†’ 4. V for 3D")
        print(f"{'=' * 80}")

    def _handle_paused_state(self):
        """å¤„ç†æš‚åœçŠ¶æ€ - ä¼˜åŒ–ç‰ˆæœ¬"""
        # åœ¨æš‚åœæ—¶ä»éœ€å¤„ç†3Då¯è§†åŒ–å’Œé”®ç›˜äº‹ä»¶
        self._handle_background_tasks()
        time.sleep(0.01)  # å°å»¶è¿Ÿé¿å…CPUå ç”¨è¿‡é«˜

    def _should_process_frame(self, current_time):
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥å¤„ç†å¸§ï¼ˆå¸§ç‡æ§åˆ¶ï¼‰"""
        elapsed_since_last_frame = current_time - self.last_frame_time
        target_frame_time = self.frame_time / self.playback_speed
        return elapsed_since_last_frame >= target_frame_time

    def _process_video_frame(self):
        """å¤„ç†è§†é¢‘å¸§ - å¢å¼ºç‰ˆæœ¬ï¼Œæ”¯æŒç½‘ç»œæ‘„åƒå¤´å’Œè¿›åº¦æ¡"""
        if self.network_mode:
            # ç½‘ç»œæ‘„åƒå¤´æ¨¡å¼
            return self._process_network_camera_frame()
        else:
            # æœ¬åœ°è§†é¢‘æ–‡ä»¶æ¨¡å¼
            return self._process_local_video_frame()
    
    def _process_network_camera_frame(self):
        """å¤„ç†ç½‘ç»œæ‘„åƒå¤´å¸§"""
        if not self.network_camera_manager:
            return False
        
        # è¯»å–æœ€æ–°å¸§
        (ret1, ret2), (frame1, frame2) = self.network_camera_manager.read()
        
        if not ret1 or not ret2 or frame1 is None or frame2 is None:
            return True  # ç½‘ç»œæµå¯èƒ½æš‚æ—¶æ— æ•°æ®ï¼Œç»§ç»­è¿è¡Œ
        
        # æ›´æ–°æ—¶é—´åŸºå‡†
        self.last_frame_time = time.time()
        
        # æ›´æ–°å¸§è®¡æ•°å’ŒFPS
        self.frame_count += 1
        self._update_fps()
        
        # æ·»åŠ åˆ°ç¼“å†²åŒºï¼ˆåªåœ¨ç¼“å†²çŠ¶æ€ä¸”æœªå¤„ç†æ—¶ï¼‰
        if self.state == SystemState.BUFFERING and not self.processing_lock:
            self.buffered_processor.add_frame_pair(frame1, frame2, self.last_frame_time)
        
        # ä¿å­˜å½“å‰å¸§ç”¨äºæ˜¾ç¤º
        self.current_frame1 = frame1.copy() if frame1 is not None else np.zeros((480, 640, 3), dtype=np.uint8)
        self.current_frame2 = frame2.copy() if frame2 is not None else np.zeros((480, 640, 3), dtype=np.uint8)
        
        return True
    
    def _process_local_video_frame(self):
        """å¤„ç†æœ¬åœ°è§†é¢‘æ–‡ä»¶å¸§"""
        # æ£€æŸ¥æ˜¯å¦æœ‰è·³è½¬è¯·æ±‚
        if self.video_controls:
            seek_requested, seek_frame = self.video_controls.is_seek_requested()
            if seek_requested:
                self._seek_to_frame(seek_frame)
                print(f"ğŸ“ Seeking to frame {seek_frame}")
        
        # è¯»å–å¸§
        ret1, frame1 = self.cap1.read()
        ret2, frame2 = self.cap2.read()

        if not ret1 or not ret2:
            return False

        # æ›´æ–°å½“å‰å¸§ç´¢å¼•
        self.current_frame_index += 1
        
        # æ›´æ–°è¿›åº¦æ¡
        if self.video_controls:
            self.video_controls.update_position(self.current_frame_index)

        # æ›´æ–°æ—¶é—´åŸºå‡†
        self.last_frame_time = time.time()

        # æ›´æ–°å¸§è®¡æ•°å’ŒFPS
        self.frame_count += 1
        self._update_fps()

        # æ·»åŠ åˆ°ç¼“å†²åŒºï¼ˆåªåœ¨ç¼“å†²çŠ¶æ€ä¸”æœªå¤„ç†æ—¶ï¼‰
        if self.state == SystemState.BUFFERING and not self.processing_lock:
            self.buffered_processor.add_frame_pair(frame1, frame2, self.last_frame_time)

        # ä¿å­˜å½“å‰å¸§ç”¨äºæ˜¾ç¤º
        self.current_frame1 = frame1 if frame1 is not None else np.zeros((480, 640, 3), dtype=np.uint8)
        self.current_frame2 = frame2 if frame2 is not None else np.zeros((480, 640, 3), dtype=np.uint8)

        return True
    
    def _seek_to_frame(self, frame_number):
        """è·³è½¬åˆ°æŒ‡å®šå¸§"""
        if self.network_mode:
            print("âš ï¸ Seeking not supported in network camera mode")
            return
        
        if self.cap1 and self.cap2:
            self.cap1.set(cv2.CAP_PROP_POS_FRAMES, frame_number)
            self.cap2.set(cv2.CAP_PROP_POS_FRAMES, frame_number)
            self.current_frame_index = frame_number
            print(f"ğŸ“ Seeked to frame {frame_number}")

    def _update_display(self):
        """æ›´æ–°æ˜¾ç¤º - å¢å¼ºç‰ˆæœ¬ï¼Œæ”¯æŒè¿›åº¦æ¡"""
        if hasattr(self, 'current_frame1') and hasattr(self, 'current_frame2'):
            display_frame = self._create_display_frame(self.current_frame1, self.current_frame2)
            if display_frame is not None:
                # åœ¨ç½‘ç»œæ‘„åƒå¤´æ¨¡å¼ä¸‹ï¼Œä¸æ˜¾ç¤ºè¿›åº¦æ¡
                if self.network_mode or not self.video_controls:
                    cv2.imshow('Enhanced Badminton System - Live View', display_frame)
                else:
                    # æœ¬åœ°è§†é¢‘æ¨¡å¼ï¼Œæ·»åŠ è¿›åº¦æ¡
                    combined_frame = self.video_controls.render_with_video(display_frame)
                    if combined_frame is not None:
                        cv2.imshow('Enhanced Badminton System - Live View', combined_frame)
                        # è®¾ç½®é¼ æ ‡å›è°ƒï¼ˆä»…ç¬¬ä¸€æ¬¡ï¼‰
                        self.video_controls.set_mouse_callback('Enhanced Badminton System - Live View')
                    else:
                        cv2.imshow('Enhanced Badminton System - Live View', display_frame)

    def _handle_background_tasks(self):
        """å¤„ç†èƒŒæ™¯ä»»åŠ¡ - ä¼˜åŒ–ç‰ˆæœ¬"""
        # 1. æ›´æ–°3Då¯è§†åŒ–ï¼ˆéé˜»å¡ï¼‰
        if self.interactive_3d_viz:
            try:
                self.interactive_3d_viz.update_if_visible()
            except Exception as e:
                print(f"âš ï¸ 3D visualization background update error: {e}")

        # 2. å¤„ç†é”®ç›˜äº‹ä»¶
        key = cv2.waitKey(1) & 0xFF
        if key != 255:  # æœ‰æŒ‰é”®
            self._handle_keyboard_input(key, time.time())

    def _monitor_performance(self):
        """æ€§èƒ½ç›‘æ§"""
        # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æ€§èƒ½ç›‘æ§é€»è¾‘
        pass

    def _handle_keyboard_input(self, key, current_time):
        """ç»Ÿä¸€çš„é”®ç›˜äº‹ä»¶å¤„ç† - å®Œå…¨é‡å†™"""
        if key == 27:  # ESC - é€€å‡º
            self.running = False
            print("ğŸšª Exit requested by user")

        elif key == ord(' '):  # SPACE - æš‚åœ/æ¢å¤æ’­æ”¾
            self._handle_space_key()

        elif key == ord('t') or key == ord('T'):  # T - è§¦å‘é¢„æµ‹
            self._handle_prediction_trigger(current_time)

        elif key == ord('p') or key == ord('P'):  # P - æ¢å¤æ’­æ”¾
            self._handle_resume_playback()

        elif key == ord('v') or key == ord('V'):  # V - åˆ‡æ¢3Då¯è§†åŒ–
            self._handle_toggle_3d_visualization()

        elif key == ord('q') or key == ord('Q'):  # Q - å…³é—­3Dçª—å£
            self._handle_close_3d_window()

        elif key == ord('d') or key == ord('D'):  # D - æ‰“å°è°ƒè¯•ç»Ÿè®¡
            self._handle_debug_statistics()

        elif key == ord('h') or key == ord('H'):  # H - å¸®åŠ©
            UIHelper.display_help_screen()

        elif key == ord('r') or key == ord('R'):  # R - é‡ç½®ç³»ç»Ÿ
            self._handle_system_reset()

        elif key == ord('+') or key == ord('='):  # å¢åŠ æ’­æ”¾é€Ÿåº¦
            self._handle_speed_change(1.2)

        elif key == ord('-') or key == ord('_'):  # å‡å°‘æ’­æ”¾é€Ÿåº¦
            self._handle_speed_change(1 / 1.2)

        elif key == ord('0'):  # é‡ç½®åˆ°æ­£å¸¸é€Ÿåº¦
            self._handle_speed_reset()

        # 3Då¯è§†åŒ–å…ƒç´ åˆ‡æ¢
        elif key in [ord('1'), ord('2'), ord('3'), ord('4'), ord('5'), ord('6')]:
            self._handle_3d_element_toggle(key)

    def _handle_space_key(self):
        """å¤„ç†ç©ºæ ¼é”® - æš‚åœ/æ¢å¤"""
        if self.paused:
            print("\nğŸ“‹ Video is paused. Choose action:")
            print("   P - Resume playback")
            print("   T - Trigger trajectory analysis and prediction")
            print("   V - Open 3D visualization (if data available)")
        else:
            self.paused = True
            print("â¸ï¸  Video PAUSED")
            print("   Press P to resume playback")
            print("   Press T to analyze current trajectory")

    def _handle_prediction_trigger(self, current_time):
        """å¤„ç†é¢„æµ‹è§¦å‘ - å¢å¼ºç‰ˆæœ¬"""
        # æ£€æŸ¥æ˜¯å¦æš‚åœ
        if not self.paused:
            print("âŒ Please pause video first (SPACE), then press T to predict")
            return

        # æ£€æŸ¥ç³»ç»ŸçŠ¶æ€
        if self.processing_lock or self.state != SystemState.BUFFERING:
            print("âŒ System busy. Please wait for current operation to complete.")
            return

        # æ£€æŸ¥å†·å´æ—¶é—´
        if current_time - self.last_prediction_time < self.prediction_cooldown:
            remaining_time = self.prediction_cooldown - (current_time - self.last_prediction_time)
            print(f"â±ï¸ Prediction cooldown: {remaining_time:.1f}s remaining")
            return

        # æ£€æŸ¥ç¼“å†²åŒº
        buffer_info = self.buffered_processor.get_buffer_info()
        if buffer_info['buffer_size'] < 10:
            print(f"âŒ Insufficient buffered frames: {buffer_info['buffer_size']}/10 minimum")
            return

        # è®¾ç½®å¤„ç†é”å’ŒçŠ¶æ€
        self.processing_lock = True
        self.last_prediction_time = current_time

        # è§¦å‘å¤„ç†
        success = self.buffered_processor.trigger_processing(self._on_processing_complete)

        if success:
            self.state = SystemState.PROCESSING
            print("ğŸ¯ TRAJECTORY ANALYSIS STARTED...")
            print(f"   Processing {buffer_info['buffer_size']} buffered frames")
            print("   Please wait for prediction results...")
        else:
            print("âŒ Failed to start processing")
            self.processing_lock = False

    def _handle_resume_playback(self):
        """å¤„ç†æ¢å¤æ’­æ”¾"""
        if self.paused:
            self.paused = False
            self.last_frame_time = time.time()
            print("â–¶ï¸  Playback RESUMED")
        else:
            print("â„¹ï¸  Video is already playing")

    def _handle_toggle_3d_visualization(self):
        """å¤„ç†3Då¯è§†åŒ–åˆ‡æ¢"""
        if not self.interactive_3d_viz:
            print("âŒ 3D visualizer not available")
            return

        if self.prediction_result or self.current_trajectory_data:
            try:
                self.interactive_3d_viz.toggle_window()
            except Exception as e:
                print(f"âŒ Error toggling 3D visualization: {e}")
        else:
            print("âŒ No prediction data available for 3D visualization")
            print("   Please run trajectory analysis first (T key when paused)")

    def _handle_close_3d_window(self):
        """å¤„ç†å…³é—­3Dçª—å£"""
        if self.interactive_3d_viz and self.interactive_3d_viz.window_visible:
            try:
                self.interactive_3d_viz.close_window()
                print("âœ… 3D visualization window closed")
            except Exception as e:
                print(f"âš ï¸ Error closing 3D window: {e}")
        else:
            print("â„¹ï¸  3D visualization window is not currently open")

    def _handle_debug_statistics(self):
        """å¤„ç†è°ƒè¯•ç»Ÿè®¡æ‰“å°"""
        if self.interactive_3d_viz:
            try:
                self.interactive_3d_viz.print_debug_statistics()
            except Exception as e:
                print(f"âŒ Error printing debug statistics: {e}")
        else:
            print("âŒ 3D visualizer not available for debug statistics")

    def _handle_system_reset(self):
        """å¤„ç†ç³»ç»Ÿé‡ç½® - å®Œå…¨é‡å†™"""
        if self.processing_lock or self.state == SystemState.PROCESSING:
            print("âŒ Cannot reset while processing. Please wait.")
            return

        try:
            print("ğŸ”„ Performing COMPLETE system reset...")

            # 1. å…³é—­å¹¶é‡ç½®3Då¯è§†åŒ–
            if self.interactive_3d_viz:
                if self.interactive_3d_viz.window_visible:
                    self.interactive_3d_viz.close_window()
                self.interactive_3d_viz.reset()

            # 2. é‡ç½®ç¼“å†²å¤„ç†å™¨
            if self.buffered_processor:
                self.buffered_processor.clear_buffer()
                # å¼ºåˆ¶é‡ç½®å¤„ç†çŠ¶æ€
                if hasattr(self.buffered_processor, 'force_reset_processing_state'):
                    self.buffered_processor.force_reset_processing_state()
                else:
                    self.buffered_processor.is_processing = False

            # 3. é‡ç½®åŒç›®å¤„ç†å™¨
            if self.stereo_processor:
                self.stereo_processor.reset()

            # 4. æ¸…ç†ç³»ç»ŸçŠ¶æ€
            self.prediction_result = None
            self.current_trajectory_data = None
            self.state = SystemState.BUFFERING
            self.processing_lock = False

            # 5. é‡ç½®è®¡æ•°å’Œæ—¶é—´
            self.last_prediction_time = 0
            self.last_frame_time = time.time()

            # 6. é‡ç½®æ’­æ”¾çŠ¶æ€
            if self.paused:
                self.paused = False
                print("â–¶ï¸  Video playback resumed after reset")

            print("âœ… COMPLETE system reset successful")
            print("ğŸ“º System ready for new trajectory analysis")
            print(f"ğŸ”„ Reset completed at {time.strftime('%H:%M:%S')} UTC")

        except Exception as e:
            print(f"âš ï¸ Error during system reset: {e}")
            # å¼ºåˆ¶é‡ç½®å…³é”®çŠ¶æ€
            self.state = SystemState.BUFFERING
            self.processing_lock = False
            if self.buffered_processor:
                self.buffered_processor.is_processing = False

    def _handle_speed_change(self, factor):
        """å¤„ç†æ’­æ”¾é€Ÿåº¦å˜åŒ–"""
        self.playback_speed = max(0.1, min(5.0, self.playback_speed * factor))
        print(f"â© Playback speed: {self.playback_speed:.1f}x")

    def _handle_speed_reset(self):
        """é‡ç½®æ’­æ”¾é€Ÿåº¦"""
        self.playback_speed = 1.0
        print("â–¶ï¸  Playback speed reset to 1.0x")

    def _handle_3d_element_toggle(self, key):
        """å¤„ç†3Då…ƒç´ åˆ‡æ¢"""
        if not self.interactive_3d_viz:
            print("âŒ 3D visualizer not available")
            return

        element_map = {
            ord('1'): 'all_valid',
            ord('2'): 'prediction',
            ord('3'): 'rejected',
            ord('4'): 'low_quality',
            ord('5'): 'triangulation_failed',
            ord('6'): 'predicted_trajectory'
        }

        element_type = element_map.get(key)
        if element_type:
            try:
                self.interactive_3d_viz.toggle_visualization_elements(element_type)
            except Exception as e:
                print(f"âŒ Error toggling 3D element: {e}")

    def _create_display_frame(self, frame1, frame2):
        """åˆ›å»ºæ˜¾ç¤ºå¸§ - å®Œå…¨é‡å†™"""
        if frame1 is None and frame2 is None:
            return None

        # è°ƒæ•´å¸§å¤§å°
        display_height = 480
        display_width = 640

        if frame1 is not None:
            frame1_resized = cv2.resize(frame1, (display_width, display_height))
        else:
            frame1_resized = np.zeros((display_height, display_width, 3), dtype=np.uint8)

        if frame2 is not None:
            frame2_resized = cv2.resize(frame2, (display_width, display_height))
        else:
            frame2_resized = np.zeros((display_height, display_width, 3), dtype=np.uint8)

        # æ°´å¹³æ‹¼æ¥ä¸»è§†é¢‘
        combined_frame = np.hstack([frame1_resized, frame2_resized])

        # åˆ›å»ºå¢å¼ºçŠ¶æ€æ 
        status_bar = self._create_enhanced_status_bar(combined_frame.shape[1])

        # å‚ç›´æ‹¼æ¥
        final_frame = np.vstack([combined_frame, status_bar])

        return final_frame

    def _create_enhanced_status_bar(self, width):
        """åˆ›å»ºå¢å¼ºçŠ¶æ€æ """
        status_bar = np.zeros((160, width, 3), dtype=np.uint8)

        # ç³»ç»ŸçŠ¶æ€æ˜¾ç¤º
        state_colors = {
            SystemState.BUFFERING: (0, 255, 0),
            SystemState.PROCESSING: (255, 255, 0),
            SystemState.PREDICTION_READY: (255, 165, 0),
            SystemState.PREDICTION_COMPLETE: (0, 255, 255)
        }

        state_color = state_colors.get(self.state, (255, 255, 255))
        state_text = f"State: {self.state.value.upper()}"
        if self.processing_lock:
            state_text += " [LOCKED]"

        cv2.putText(status_bar, state_text, (10, 25),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, state_color, 2)

        # 3Dçª—å£çŠ¶æ€
        if self.interactive_3d_viz:
            viz_status = "OPEN" if self.interactive_3d_viz.window_visible else "CLOSED"
            viz_color = (0, 255, 255) if self.interactive_3d_viz.window_visible else (100, 100, 100)
            cv2.putText(status_bar, f"3D Debug: {viz_status}", (350, 25),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, viz_color, 2)

        # æ—¶é—´å’Œç”¨æˆ·ä¿¡æ¯
        current_time_str = time.strftime('%H:%M:%S UTC')
        cv2.putText(status_bar, f"Time: {current_time_str}", (650, 25),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

        cv2.putText(status_bar, f"User: Liao-cyber360", (900, 25),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)

        # ç¼“å†²åŒºå’Œæ€§èƒ½ä¿¡æ¯
        if self.buffered_processor:
            buffer_info = self.buffered_processor.get_buffer_info()
            cv2.putText(status_bar, f"Buffer: {buffer_info['buffer_size']}/{buffer_info['max_size']} frames",
                        (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

        # æ’­æ”¾çŠ¶æ€
        if self.paused:
            pause_text = "[â¸ï¸  PAUSED - T:Predict P:Resume]"
            pause_color = (0, 255, 255)
        else:
            pause_text = f"[â–¶ï¸  PLAYING - Speed: {self.playback_speed:.1f}x]"
            pause_color = (255, 255, 255)

        cv2.putText(status_bar, pause_text, (350, 50),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, pause_color, 1)

        # FPSå’Œå¸§ä¿¡æ¯
        cv2.putText(status_bar, f"FPS: {self.actual_fps:.1f} | Frame: {self.frame_count}",
                    (650, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

        # é¢„æµ‹ç»Ÿè®¡
        if self.total_predictions > 0:
            success_rate = (self.successful_predictions / self.total_predictions) * 100
            cv2.putText(status_bar,
                        f"Predictions: {self.successful_predictions}/{self.total_predictions} ({success_rate:.1f}%)",
                        (10, 75), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)

        # è°ƒè¯•æ•°æ®æ˜¾ç¤º
        if self.current_trajectory_data and 'debug_data' in self.current_trajectory_data:
            debug_data = self.current_trajectory_data['debug_data']
            debug_text = f"Debug: V:{len(debug_data.get('all_valid_points', []))} P:{len(debug_data.get('prediction_points', []))} R:{len(debug_data.get('rejected_points', []))}"
            cv2.putText(status_bar, debug_text, (350, 75),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 255), 1)

        # æ§åˆ¶æç¤ºè¡Œ1
        if self.paused:
            controls1 = "â¸ï¸  PAUSED: T:Predict | P:Resume | V:3D | D:Debug | R:Reset | H:Help"
        else:
            controls1 = "â–¶ï¸  PLAYING: SPACE:Pause | V:3D | D:Debug | R:Reset | H:Help"

        cv2.putText(status_bar, controls1, (10, 105),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.4, (200, 200, 200), 1)

        # æ§åˆ¶æç¤ºè¡Œ2
        controls2 = "3D Controls: 1:AllValid 2:Prediction 3:Rejected 4:LowQuality 5:TriFailed 6:Trajectory"
        cv2.putText(status_bar, controls2, (10, 125),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.35, (150, 200, 255), 1)

        # æ§åˆ¶æç¤ºè¡Œ3
        controls3 = "Playback: +/-:Speed 0:Reset | System: Q:Close3D ESC:Exit"
        cv2.putText(status_bar, controls3, (10, 145),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.35, (150, 200, 255), 1)

        return status_bar

    def _update_fps(self):
        """æ›´æ–°FPSè®¡ç®—"""
        current_time = time.time()
        self.fps_counter += 1

        if current_time - self.fps_prev_time >= 1.0:
            self.actual_fps = self.fps_counter
            self.fps_counter = 0
            self.fps_prev_time = current_time

    def _cleanup(self):
        """æ¸…ç†ç³»ç»Ÿèµ„æº - å¢å¼ºç‰ˆæœ¬ï¼Œæ”¯æŒç½‘ç»œæ‘„åƒå¤´"""
        print("\nğŸ”„ Cleaning up system resources...")

        try:
            # åœæ­¢ç½‘ç»œæ‘„åƒå¤´
            if self.network_camera_manager:
                self.network_camera_manager.stop()

            # åœæ­¢è§†é¢‘æ•è·
            if self.cap1:
                self.cap1.release()
            if self.cap2:
                self.cap2.release()

            # åœæ­¢3Då¯è§†åŒ–
            if self.interactive_3d_viz:
                self.interactive_3d_viz.stop()

            # å…³é—­OpenCVçª—å£
            cv2.destroyAllWindows()

            # æ‰“å°ä¼šè¯ç»Ÿè®¡
            session_duration = time.time() - self.system_start_time
            print(f"\nğŸ“Š SESSION STATISTICS:")
            print(f"   Duration: {session_duration:.1f} seconds")
            print(f"   Frames processed: {self.frame_count}")
            print(f"   Predictions attempted: {self.total_predictions}")
            print(f"   Successful predictions: {self.successful_predictions}")
            if self.total_predictions > 0:
                success_rate = (self.successful_predictions / self.total_predictions) * 100
                print(f"   Success rate: {success_rate:.1f}%")
            
            mode_text = "Network Camera" if self.network_mode else "Local Video"
            print(f"   Mode: {mode_text}")

        except Exception as e:
            print(f"âš ï¸ Error during cleanup: {e}")

        print("âœ… System cleanup complete")
        print(f"Session ended at: {time.strftime('%Y-%m-%d %H:%M:%S')} UTC")
        print(f"User: Liao-cyber360")


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="Enhanced Buffered Badminton Landing Prediction System v5.2 - Network Camera Support"
    )

    # åˆ›å»ºäº’æ–¥ç»„ï¼šæœ¬åœ°è§†é¢‘æˆ–ç½‘ç»œæ‘„åƒå¤´
    mode_group = parser.add_mutually_exclusive_group(required=True)
    
    # æœ¬åœ°è§†é¢‘æ¨¡å¼
    mode_group.add_argument("--video-mode", action="store_true",
                           help="Use local video files")
    
    # ç½‘ç»œæ‘„åƒå¤´æ¨¡å¼
    mode_group.add_argument("--camera-mode", action="store_true",
                           help="Use network cameras (MJPEG streams)")

    # æœ¬åœ°è§†é¢‘å‚æ•°
    parser.add_argument("--video1", type=str,
                        help="Path to first camera video file (required for --video-mode)")
    parser.add_argument("--video2", type=str,
                        help="Path to second camera video file (required for --video-mode)")
    
    # ç½‘ç»œæ‘„åƒå¤´å‚æ•°
    parser.add_argument("--camera-url1", type=str,
                        help="URL for first camera MJPEG stream (required for --camera-mode)")
    parser.add_argument("--camera-url2", type=str,
                        help="URL for second camera MJPEG stream (optional for --camera-mode)")
    parser.add_argument("--timestamp-header", type=str, default="X-Timestamp",
                        help="HTTP header name for timestamp (default: X-Timestamp)")
    
    # æ ‡å®šå‚æ•°
    parser.add_argument("--calibrated", action="store_true",
                        help="Skip calibration if cameras are already calibrated")
    parser.add_argument("--cam1_params", type=str, default=None,
                        help="Path to camera 1 parameters file")
    parser.add_argument("--cam2_params", type=str, default=None,
                        help="Path to camera 2 parameters file")

    return parser.parse_args()


def main():
    """ä¸»å‡½æ•° - å¢å¼ºç‰ˆæœ¬ï¼Œæ”¯æŒç½‘ç»œæ‘„åƒå¤´"""
    try:
        print("=" * 80)
        print("Enhanced Buffered Badminton Shuttlecock Landing Prediction System v5.2")
        print("Network Camera Support with Multi-Object Tracking")
        print("=" * 80)
        print(f"Session started at: {time.strftime('%Y-%m-%d %H:%M:%S')} UTC")
        print(f"Current User: Liao-cyber360")
        print(f"Features: Network cameras, Progress bar, Multi-shuttlecock tracking, Max speed calculation")
        print("=" * 80)

        args = parse_arguments()

        # åˆ›å»ºå’Œåˆå§‹åŒ–ç³»ç»Ÿ
        system = BufferedBadmintonSystem()
        
        # æ ¹æ®æ¨¡å¼åˆå§‹åŒ–
        if args.video_mode:
            # æœ¬åœ°è§†é¢‘æ¨¡å¼
            if not args.video1 or not args.video2:
                raise ValueError("--video1 and --video2 are required for --video-mode")
            
            # éªŒè¯è§†é¢‘æ–‡ä»¶
            if not os.path.exists(args.video1):
                raise FileNotFoundError(f"Video file not found: {args.video1}")
            if not os.path.exists(args.video2):
                raise FileNotFoundError(f"Video file not found: {args.video2}")

            print(f"ğŸ“¹ Local Video Mode:")
            print(f"   Camera 1: {args.video1}")
            print(f"   Camera 2: {args.video2}")
            
            system.initialize_system(args.video1, args.video2)
            
        elif args.camera_mode:
            # ç½‘ç»œæ‘„åƒå¤´æ¨¡å¼
            if not args.camera_url1:
                raise ValueError("--camera-url1 is required for --camera-mode")
            
            print(f"ğŸŒ Network Camera Mode:")
            print(f"   Camera 1: {args.camera_url1}")
            if args.camera_url2:
                print(f"   Camera 2: {args.camera_url2}")
            else:
                print(f"   Camera 2: Single camera mode")
            print(f"   Timestamp header: {args.timestamp_header}")
            
            system.initialize_network_cameras(
                args.camera_url1, 
                args.camera_url2, 
                args.timestamp_header
            )

        # å¤„ç†æ ‡å®š
        if args.calibrated and args.cam1_params and args.cam2_params:
            if os.path.exists(args.cam1_params) and os.path.exists(args.cam2_params):
                system.load_existing_calibration(args.cam1_params, args.cam2_params)
            else:
                print("âš ï¸ Warning: Calibration files not found, starting calibration...")
                if not system.calibration_mode():
                    raise RuntimeError("Calibration failed")
        else:
            print("ğŸ¯ Starting camera calibration process...")
            if not system.calibration_mode():
                raise RuntimeError("Calibration failed")

        print("\n" + "=" * 80)
        print("âœ… SYSTEM READY - Starting Enhanced Video Processing")
        if system.network_mode:
            print("ğŸŒ Network Camera Mode - Progress bar disabled")
            print("ğŸ“¡ Stream buffering active - Use pause for trajectory analysis")
        else:
            print("ğŸ“¹ Local Video Mode - Progress bar enabled")
            print("ğŸ® Drag progress bar to seek, pause for trajectory analysis")
        print("=" * 80)

        # å¼€å§‹ä¸»å¤„ç†å¾ªç¯
        system.start_processing()

    except KeyboardInterrupt:
        print(f"\n{'=' * 80}")
        print("âš ï¸ Program interrupted by user (Ctrl+C)")
        print(f"Session ended at: {time.strftime('%Y-%m-%d %H:%M:%S')} UTC")
        print(f"{'=' * 80}")
    except FileNotFoundError as e:
        print(f"âŒ File Error: {e}")
    except RuntimeError as e:
        print(f"âŒ Runtime Error: {e}")
    except Exception as e:
        print(f"âŒ Unexpected error in main: {e}")
        import traceback
        traceback.print_exc()
        print(f"\nSession ended with error at: {time.strftime('%Y-%m-%d %H:%M:%S')} UTC")
    finally:
        cv2.destroyAllWindows()
        print("\nâœ… All resources cleaned up successfully.")
        print("Thank you for using Enhanced Badminton Prediction System v5.2")


if __name__ == "__main__":
    main()